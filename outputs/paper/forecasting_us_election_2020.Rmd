---
title: "Joe Biden projected to win Popular Vote in 2020 US Election with 51% of Vote"
author: "Alen Mitrovski, Xiaoyan Yang, Matthew Wankiewicz"
date: "November 2nd, 2020"
abstract: |
  | First sentence. Second sentence. Third sentence. Fourth sentence.
  |
  | **Keywords:** Forecasting, US 2020 Election, Trump, Biden, multilevel regression with post-stratification;
output:
  bookdown::pdf_document2:
    citation_package: natbib
toc: FALSE
bibliography: references.bib
---

```{r, echo=F, message=F, warning=F}
#install.packages("tidyverse")
#install.packages("gtsummary")
#install.packages("statebins")
#install.packages("broom")
library(tidyverse)
library(statebins)
library(broom)
```

```{r, echo=F, message=F, warning=F}
# read in the polling data
polling <- readRDS("polling_data.rds")

# read in post-strat data 
post_strat <- readRDS("post_strat.rds")
post_strat <- post_strat %>% 
  filter(race != "two major races", race != "three or more major races",
         age >= 18)

# read in electoral colleges data
elec_college <- read_csv("electoral_colleges.csv")
elec_college$State <- tolower(elec_college$State)
```

# Introduction

# Data

We have used R (@citeR), specifically Tidyverse (@citeTidyverse) for data analysis

Data is from ACS (@citeIPUMS) and from Voter Study Group (@citeVSG).

```{r data1, echo=F, message=F, warning=F, fig.cap="Demographics of Sample and Population"}

# set up proportions and plots for polling data (variables we focus on)
gender <- polling %>% 
  group_by(sex) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "poll",
         group = "gender") %>% 
  rename(level = sex)

races <- polling %>% 
  group_by(races) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "poll",
         group = "races") %>% 
  rename(level = races)

education <- polling %>% 
  group_by(education_level) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "poll",
         group = "education") %>% 
  drop_na(education_level) %>% 
  rename(level = education_level)

age <- polling %>% 
  group_by(age_groups) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "poll",
         group = "age") %>% 
  rename(level = age_groups)

statesicp <- polling %>% 
  group_by(stateicp) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "poll",
         group = "state") %>% 
   rename(level = stateicp)

hispanic <- polling %>% 
  group_by(hispan) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "poll",
         group = "hispanic") %>% 
   rename(level = hispan)

# set up proportions for post-strat data

gender_post <- post_strat %>% 
  group_by(sex) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "post_strat",
         group = "gender") %>% 
  rename(level = sex)

races_post <- post_strat %>% 
  group_by(races) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "post_strat",
         group = "races") %>% 
  rename(level = races)

education_post <- post_strat %>% 
  group_by(education_level) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "post_strat",
         group = "education") %>% 
  rename(level = education_level)

age_post <- post_strat %>% 
  group_by(age_groups) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "post_strat",
         group = "age") %>% 
  rename(level = age_groups)

statesicp_post <- post_strat %>% 
  group_by(stateicp) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "post_strat",
         group = "state") %>% 
  rename(level = stateicp)

hispanic_post <- post_strat %>% 
  group_by(hispan) %>% 
  summarise(n = n()) %>% 
  mutate(pct = n/sum(n), type = "post_strat",
         group = "hispanic") %>% 
  rename(level = hispan)

variables <- rbind(hispanic, hispanic_post,
             age, age_post, gender, gender_post, 
             races, races_post)

variables %>% ggplot(aes(as.factor(level), pct, group=as.factor(type), linetype = as.factor(type))) + 
  geom_line() + facet_wrap(~group, scales = "free", ncol = 5) + 
  theme(axis.text.x = element_text(angle=70, size = 6, hjust = 1)) +
  labs(x = "category", y = "percentage", linetype = "data set") + 
  scale_y_continuous(labels = scales::percent)
```

Figure \@ref(fig:data) show us the voter demographics from the VSG data (@citeVSG) vs the ACS data (@citeIPUMS).


```{r data2, echo = F, message=F, warning=F, fig.cap="More Demographics of Sample and Population"}
variables2 <- rbind(education, education_post,
                    statesicp, statesicp_post)
variables2 %>% ggplot(aes(as.factor(level), pct, group=as.factor(type), linetype = as.factor(type))) + 
  geom_line() + facet_wrap(~group, nrow = 2, scales = "free") + 
  theme(axis.text.x = element_text(angle=70, size = 6, hjust = 1)) +
  labs(x = "category", y = "percentage", linetype = "data set") +
  scale_y_continuous(labels = scales::percent)
```

Figure \@ref(fig:data2) show us more of the voter demographics from the VSG data (@citeVSG) vs the ACS data (@citeIPUMS).

# Model

In order to predict whether or not a person plans to vote for Joe Biden or Donald Trump, we plan to use logistic regression. Since logistic regression only works for binary response variables, we used a variable we created called `vote_biden` which returns a 1 is the respondent plan to vote for Joe Biden and a 0 if they don't (in this scenario we assume that they are voting for Donald Trump). The logistic regression model takes the form of:

$$  
log(\frac{\hat{p}}{1 - \hat{p}}) = \beta_{0} + \beta_{1}x_{sex} + 
\beta_{2}x_{agegroup} + \beta_{3}x_{race} + \beta_{4}x_{state} + \beta_{5}x_{income} + \beta_{6}x_{hispanic}
$$
In the equation above, each $\beta$ represents a coefficient that the regression model will compute for us. As for our variables, we have chosen to use sex, age, race, income, state, and whether the respondent is hispanic. We decided to use the first 3 because they are generally strong predictors of which candidate a person would support, such as how some states tend to vote republican year after year while some states flip between democratic and republican almost every election. Next, we decided to choose income, because Joe Biden has made claims to increase taxes on the rich, which may influence their support for him. Lastly, we wanted to focus on whether the respondent was hispanic and if so, where they were from. This variable was important for our predictions because we know how poorly Donald Trump has spoken of hispanic people and we believe they could have a strong impact on the election.

The output of the logistic regression model will give us a probability of whether or not a voter plans to vote for Joe Biden or not. In order to find this probability, we take the sum of the right side of the equation and plug it into the equation below:

$$
\frac{e^{sum}}{1+e^{sum}}
$$

This equation is just a manipulation of the initial equation, where e is the exponential equation ad sum is the sum of the right side of equation 1. We see that as the sum of the right side increases, the probability that a person will vote for Joe Biden increases as well. 

We are running our regression model using the glm() function in R (@citeR). The decision to run this model over other models like linear regression was made by the fact that we were predicting a binary variable about a voter's decision. Since there are only two possible options our data will likely follow an S shape and a straight line equation will not be helpful to model this relationship. 

Our model does have some weaknesses, since the output must be binary, we cannot account for other candidates or a person deciding not to vote. This issue isn't too large because our main goal is to determine which of the two main candidates will be chosen by the people of America. Another weakness our model does encounter is that 

```{r model, echo = F, message=F, warning=F, fig.cap="Results of Regression Model"}
model2 <- glm(vote_biden ~ sex + age_groups + races +
               stateicp + education_level + hispan, 
             data = polling, family = binomial())

coefficients <- broom::tidy(model2, conf.int = T)

#gtsummary::tbl_regression(model2)
```


```{r coefficients, echo=F, message=F, warning=F, fig.height=4, fig.cap="Coefficient Estimates"}
coefficients %>% ggplot(aes(estimate, term)) +
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) +
  labs(title = "Coefficient Estimates",
       x = "Estimate", y = "Coefficient")
```

Figure \@ref(coefficients) show us... using the polling data (@citeVSG).

# Results

```{r prediction, echo=F, warning=F, message=F}
# get proportions by demographic, then find proportion of each cell relative to population
props <- post_strat %>% 
  group_by(stateicp, races, age_groups,
           sex, education_level, hispan) %>% 
  summarise(n = n()) %>% 
  group_by(stateicp) %>% 
  mutate(prop = n/sum(n))

# generate predictions for each of our grouped cells
props$estimate <- predict.glm(model2, newdata = props,
                          type = "response")

# create a new column with number of voters from each cell voting Biden
props <- props %>% mutate(num_voters = n*estimate)

# get errors for our prediction
errors <- predict.glm(model2, newdata = props,
                      type = "response", se.fit = T)
lower <- errors$fit - errors$se.fit
upper <- errors$fit + errors$se.fit


# combine the proportions and the errors we generated
props_error <- cbind(props, lower, upper)
props_error <- props_error %>% 
  rename("lower" = ...11,
         "upper" = ...12)

# create a new column with number of voters from each cell voting Biden
props_error <- props_error %>% mutate(num_voters_lower = n*lower,
                                num_voters_upper = n*upper)

# create a new dataset which contains upper and lower estimates for proportions
# of votes for each state
voting_biden <- props_error %>% mutate(biden_predict_prop=estimate*prop,
                                       biden_predict_prop_lower = lower*prop,
                                       biden_predict_prop_upper = upper*prop) %>%
  group_by(stateicp) %>%
  summarise(biden_predict = sum(biden_predict_prop),
            biden_predict_lower = sum(biden_predict_prop_lower),
            biden_predict_upper = sum(biden_predict_prop_upper))
```



# Results

```{r stateplot, echo=F, message=F, warning=F, fig.cap="Proportion of each State Voting for Biden"}
# get state by state proportions for our polling data
polling_props <- polling %>% 
  group_by(stateicp, vote_biden) %>% 
  summarise(n = n()) %>% 
  mutate(prop = n/sum(n)) 

# combine the polling data proportions with the post-stratification data
poll_post_biden <- inner_join(polling_props, voting_biden, by = "stateicp")
poll_post_biden <- poll_post_biden %>% 
  filter(vote_biden == 1)

# plot for predictions

poll_post_biden %>% 
  ggplot(aes(x = stateicp, y = biden_predict)) +
  geom_point(aes(color = "black")) +
  geom_line(aes(group = 1)) +
  scale_y_continuous(labels = scales::percent) +
  theme(axis.text.x = element_text(angle = 70, size = 6, hjust = 1)) +
  geom_ribbon(aes(group = 1, ymin=biden_predict_lower, ymax=biden_predict_upper), 
              alpha = 0.2, fill = "red") +
  geom_line(data = poll_post_biden, aes(x=stateicp, y=prop, group = 2), 
            linetype = "dashed") +
  geom_point(data = poll_post_biden, aes(x=stateicp, y=prop, colour = "red")) +
  geom_hline(aes(yintercept = 0.5), linetype = "dashed") +
  scale_color_discrete(name = "Data", labels = c("Population", "Sample")) +
  labs(title = "Proportion of People voting for Joe Biden by State",
       x = "State", y = "Percentage Voting Biden")
```


Figure \@ref(fig:stateplot) show us...

```{r statemap, echo=F, message=F, warning=F, fig.cap="Proportion of Voters from Each State Voting Joe Biden"}
# plot state map

voting_biden %>% 
  mutate(statename = str_to_title(stateicp)) %>% 
  ggplot(aes(fill = biden_predict, state = statename)) + 
  geom_statebins() + 
  scale_fill_gradient2(low = "#d12531", high = "#244999",
                       mid = "white", midpoint = mean(voting_biden$biden_predict)) +
  theme_classic() +
  theme(axis.line = element_blank(),
        axis.text = element_blank(),
        axis.ticks = element_blank()) +
  labs(fill = "Proportion Voting \nfor Biden",
       title = "Map of the USA and which states plan to support Joe Biden or Donald Trump")
```

Figure \@ref(statemap) is an amazing view of all the states and which candidate they are leaning towards voting for. We see that states like Vermont, Conneticut and California are some of the more "blue" states, meaning they plan to vote for Joe Biden, while North Dakota, Arkansas and Idaho are the "red" states, planning to vote for Donald Trump. The states that are more white in colour can be the most important for the race when it comes to deciding an actual winner through the electoral college. We see that Florida, Louisiana and New Hampshire are some of the more undecided states, and a switch in these states, can influence the election greatly.

```{r colleges, echo=F, message=F, warning=F}
# merge our electoral college data with predictions from model
states_biden_prop <- voting_biden %>%
  rename("State" = stateicp)
states_college <- inner_join(states_biden_prop, elec_college, by = "State")

# create new variables finding the upper, lower and mean prediction for number of colleges
states_college <- states_college %>% 
  mutate(biden_collges = case_when(
    State == "Nebraska" ~ round(biden_predict*Number_of_colleges),
    State == "Maine" ~ round(biden_predict*Number_of_colleges),
    State != "Maine" | State != "Nebraska" ~ ifelse(biden_predict >= 0.5, Number_of_colleges, 0)
  ),
  biden_collges_lower = case_when(
    State == "Nebraska" ~ round(biden_predict_lower*Number_of_colleges),
    State == "Maine" ~ round(biden_predict_lower*Number_of_colleges),
    State != "Maine" | State != "Nebraska" ~ ifelse(biden_predict_lower >= 0.5, Number_of_colleges, 0)),
  biden_collges_upper = case_when(
    State == "Nebraska" ~ round(biden_predict_upper*Number_of_colleges),
    State == "Maine" ~ round(biden_predict_upper*Number_of_colleges),
    State != "Maine" | State != "Nebraska" ~ ifelse(biden_predict_upper >= 0.5, Number_of_colleges, 0)))


# compile upper, lower and mean number of colleges won, plus proportion of popular vote 
biden_upper <- c(round(sum(states_college$biden_collges_upper)), 
                 (round(100*sum(props_error$num_voters_upper)/sum(props_error$n),1)))
biden_mid <- c(round(sum(states_college$biden_collges)), 
                 (round(100*sum(props_error$num_voters)/sum(props_error$n), 1)))
biden_lower <- c(round(sum(states_college$biden_collges_lower)), 
                 (round(100*sum(props_error$num_voters_lower)/sum(props_error$n), 1)))

# create a dataframe with all three estimates and create a table displaying the estimates
estimates <- tibble("Lower Estimate" = biden_lower, "Mean Estimate" = biden_mid, "Upper Estimate" = biden_upper)
rownames(estimates) <- c("Number of Colleges", "Proportion of Vote")
knitr::kable(estimates, caption = "Joe Biden Voting Result Estimates")
```

Table \@ref(tab:colleges) shows the lower, mean and upper predictions for the results of the election for Joe Biden. We see that on the lower end, Biden can expect to get 45.8% of the popular vote while only getting 191 electoral colleges. We also see that our middle estimate says Biden will get 51% of the popular vote while still losing the election by getting only 260 colleges. Lastly, on the upper estimate for Biden's results, he can get 56.3% of the popular vote while getting 423 college! This truly shows how close this election is, as we can see in Figure \@ref(fig:stateplot), many states are hovering around the 50% mark, which shows the colleges can go either way.

```{r votingscales, echo=F, message=F, warning=F, fig.height=3, fig.cap="Proportion of Biden votes by state"}
poll_post_biden %>% ggplot(aes(biden_predict, stateicp)) +
  geom_point() +
  geom_errorbar(aes(xmin = biden_predict_lower, xmax = biden_predict_upper)) +
  geom_vline(xintercept = 0.5, linetype = "dashed", color = "red") +
  labs(title = "Estimated Proportion of State Voting for Joe Biden",
       x = "Percentage", y= "State") +
  scale_x_continuous(labels = scales::percent)
```

Figure \@ref(fig:votingscales) is a different view of Figure \@ref(fig:stateplot), this time only focusing on the predictions for each state with the errors included. We see that many states have error bars overlapping the 50% line, showing that many states are a toss up, given the nature of the electoral college. 

```{r cooks, echo=F, message=F, warning=F, fig.cap="Cook's Distance Plot for Model"}
plot(model2, which = 4, id.n = 3)
```

Figure \@ref(fig:cooks) shows the cooks distance for observations in our polling data set. Cook's distance is useful for checking if a model is working correctly because it tells us how far a point is from the predicted value of it, telling us which points negatively impact our model. Figure \@ref(fig:cooks) takes all observations of our polling data (@citeVSG), and calculates the Cook's distance for it, showing which points can hurt the results of our model. We find that out of the 5200 obsevations, there aren't too many points that deviate from what we predict. This makes sense for our model because in the real world, there are some people who will support Donald Trump or Joe Biden, even if they don't "fit" the usual voter demographic for the candidate. Since the number of observations with large Cook's Distances are low, we can conclude that our model is fairly strong. 

```{r residuals, echo=F, message=F, warning=F, fig.cap="Residual Plot for Model"}
model.data <- augment(model2) %>% 
  mutate(index = 1:n()) 
ggplot(model.data, aes(index, .std.resid)) + 
  geom_point(aes(color = vote_biden), alpha = .5) +
  theme_bw()
```

Figure \@ref(fig:residuals) shows us the...

# Discussion

# References


